{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16b7040b",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ff9a936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "9c0952b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7102, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>location</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Syambhunath</td>\n",
       "      <td>It is at the top of valleys mountain.  Best pl...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Syambhunath</td>\n",
       "      <td>This place has a significant importance in Bud...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Syambhunath</td>\n",
       "      <td>Visited this from the other side on a rainy ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Syambhunath</td>\n",
       "      <td>A beautiful temple situated in the capital wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Syambhunath</td>\n",
       "      <td>great, beautiful, historic &amp; religious place.....</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>7267</td>\n",
       "      <td>Pokhara</td>\n",
       "      <td>It's a nice place to sit back, and enjoy. The ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>7268</td>\n",
       "      <td>Pokhara</td>\n",
       "      <td>Excellent Place to visit, Lifetime memories</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>7269</td>\n",
       "      <td>Pokhara</td>\n",
       "      <td>It's very photogenic and relaxing when there a...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>7270</td>\n",
       "      <td>Pokhara</td>\n",
       "      <td>U can get real definition of nature's beauty a...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>7271</td>\n",
       "      <td>Pokhara</td>\n",
       "      <td>Best. Walking please beautiful views</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7102 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID     location                                             review  \\\n",
       "0        1  Syambhunath  It is at the top of valleys mountain.  Best pl...   \n",
       "1        2  Syambhunath  This place has a significant importance in Bud...   \n",
       "2        3  Syambhunath  Visited this from the other side on a rainy ev...   \n",
       "3        4  Syambhunath  A beautiful temple situated in the capital wit...   \n",
       "4        5  Syambhunath  great, beautiful, historic & religious place.....   \n",
       "...    ...          ...                                                ...   \n",
       "7097  7267      Pokhara  It's a nice place to sit back, and enjoy. The ...   \n",
       "7098  7268      Pokhara        Excellent Place to visit, Lifetime memories   \n",
       "7099  7269      Pokhara  It's very photogenic and relaxing when there a...   \n",
       "7100  7270      Pokhara  U can get real definition of nature's beauty a...   \n",
       "7101  7271      Pokhara               Best. Walking please beautiful views   \n",
       "\n",
       "      sentiment sentiment_review  \n",
       "0             1         positive  \n",
       "1             1         positive  \n",
       "2             1         positive  \n",
       "3             1         positive  \n",
       "4             1         positive  \n",
       "...         ...              ...  \n",
       "7097          1         positive  \n",
       "7098          1         positive  \n",
       "7099          1         positive  \n",
       "7100          1         positive  \n",
       "7101          1         positive  \n",
       "\n",
       "[7102 rows x 5 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing the dataset\n",
    "df=pd.read_csv('tourist sentiment.csv')\n",
    "print(df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351ab704",
   "metadata": {},
   "source": [
    "Exploratery data analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "bc2bcd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.drop(df.loc[df['sentiment']==0].index, inplace=True)\n",
    "df.drop(df.index[df['sentiment'] == 0], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ff5db5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5401.000000</td>\n",
       "      <td>5401.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3606.660804</td>\n",
       "      <td>0.920755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2155.914768</td>\n",
       "      <td>0.390176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1787.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3467.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5562.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7271.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID    sentiment\n",
       "count  5401.000000  5401.000000\n",
       "mean   3606.660804     0.920755\n",
       "std    2155.914768     0.390176\n",
       "min       1.000000    -1.000000\n",
       "25%    1787.000000     1.000000\n",
       "50%    3467.000000     1.000000\n",
       "75%    5562.000000     1.000000\n",
       "max    7271.000000     1.000000"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Summary of the dataset\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e605b7",
   "metadata": {},
   "source": [
    "Sentiment count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d967b584",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    5187\n",
       "-1     214\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sentiment count\n",
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "8dbabb4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>location</th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Syambhunath</td>\n",
       "      <td>It is at the top of valleys mountain.  Best pl...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Syambhunath</td>\n",
       "      <td>This place has a significant importance in Bud...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Syambhunath</td>\n",
       "      <td>Visited this from the other side on a rainy ev...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Syambhunath</td>\n",
       "      <td>A beautiful temple situated in the capital wit...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Syambhunath</td>\n",
       "      <td>great, beautiful, historic &amp; religious place.....</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7097</th>\n",
       "      <td>7267</td>\n",
       "      <td>Pokhara</td>\n",
       "      <td>It's a nice place to sit back, and enjoy. The ...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7098</th>\n",
       "      <td>7268</td>\n",
       "      <td>Pokhara</td>\n",
       "      <td>Excellent Place to visit, Lifetime memories</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7099</th>\n",
       "      <td>7269</td>\n",
       "      <td>Pokhara</td>\n",
       "      <td>It's very photogenic and relaxing when there a...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7100</th>\n",
       "      <td>7270</td>\n",
       "      <td>Pokhara</td>\n",
       "      <td>U can get real definition of nature's beauty a...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7101</th>\n",
       "      <td>7271</td>\n",
       "      <td>Pokhara</td>\n",
       "      <td>Best. Walking please beautiful views</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5401 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID     location                                             review  \\\n",
       "0        1  Syambhunath  It is at the top of valleys mountain.  Best pl...   \n",
       "1        2  Syambhunath  This place has a significant importance in Bud...   \n",
       "2        3  Syambhunath  Visited this from the other side on a rainy ev...   \n",
       "3        4  Syambhunath  A beautiful temple situated in the capital wit...   \n",
       "4        5  Syambhunath  great, beautiful, historic & religious place.....   \n",
       "...    ...          ...                                                ...   \n",
       "7097  7267      Pokhara  It's a nice place to sit back, and enjoy. The ...   \n",
       "7098  7268      Pokhara        Excellent Place to visit, Lifetime memories   \n",
       "7099  7269      Pokhara  It's very photogenic and relaxing when there a...   \n",
       "7100  7270      Pokhara  U can get real definition of nature's beauty a...   \n",
       "7101  7271      Pokhara               Best. Walking please beautiful views   \n",
       "\n",
       "      sentiment sentiment_review  \n",
       "0             1         positive  \n",
       "1             1         positive  \n",
       "2             1         positive  \n",
       "3             1         positive  \n",
       "4             1         positive  \n",
       "...         ...              ...  \n",
       "7097          1         positive  \n",
       "7098          1         positive  \n",
       "7099          1         positive  \n",
       "7100          1         positive  \n",
       "7101          1         positive  \n",
       "\n",
       "[5401 rows x 5 columns]"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "3b1a0336",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('tourist sentiment positive and negative.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "7a20d450",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = ['ID', 'location', 'sentiment'], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39a3e7e",
   "metadata": {},
   "source": [
    "Spliting the training dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "ecf5c8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,) (4000,)\n",
      "(1401,) (1401,)\n"
     ]
    }
   ],
   "source": [
    "#split the dataset  \n",
    "#train dataset\n",
    "train_reviews=df.review[:4000]\n",
    "train_sentiments=df.sentiment_review[:4000]\n",
    "#test dataset\n",
    "test_reviews=df.review[4000:]\n",
    "test_sentiments=df.sentiment_review[4000:]\n",
    "print(train_reviews.shape,train_sentiments.shape)\n",
    "print(test_reviews.shape,test_sentiments.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c180ba5",
   "metadata": {},
   "source": [
    "Text normalization\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "7781bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization of text\n",
    "tokenizer=ToktokTokenizer()\n",
    "#Setting English stopwords\n",
    "stopword_list=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f21231",
   "metadata": {},
   "source": [
    "Removing html strips and noise text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "f1c4d2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing the html strips\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['review']=df['review'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce86d80",
   "metadata": {},
   "source": [
    "Removing special characters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "2d063502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define function for removing special characters\n",
    "def remove_special_characters(text, remove_digits=True):\n",
    "    pattern=r'[^a-zA-z0-9\\s]'\n",
    "    text=re.sub(pattern,'',text)\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['review']=df['review'].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100fe529",
   "metadata": {},
   "source": [
    "Text stemming\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "d5c314c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming the text\n",
    "def simple_stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "#Apply function on review column\n",
    "df['review']=df['review'].apply(simple_stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881ac62b",
   "metadata": {},
   "source": [
    "Removing stopwords\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "b388886f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'there', 'if', 'more', 'so', 'were', \"mightn't\", 'now', 'd', \"didn't\", 'hasn', 'into', 'we', 'most', 'down', 'own', 'that', 'who', 'o', 'here', 'other', 'their', 'for', 're', 'be', 'once', 'wasn', 'my', 'himself', 'being', 'very', 'mightn', 'no', 'did', 'while', 'should', 'am', 'couldn', 'from', 'this', 'yourself', 's', 'with', 'by', 'these', 'not', 'his', 'was', 'until', 'your', 'weren', \"she's\", 'i', 'as', \"you'd\", 'yours', 'further', 'didn', 'is', 've', 'ma', 'when', 'had', \"wouldn't\", 'or', 'in', 'just', 'then', 'are', 'where', 'all', \"aren't\", 'y', 'them', 'those', 'myself', 'and', 'me', 'under', 'don', 'both', \"wasn't\", 'before', 'few', 'does', 'they', 'about', 'theirs', 'have', 'up', 'doesn', \"isn't\", 'of', 'on', 'aren', 'the', \"weren't\", 'any', 'after', \"hasn't\", 'how', \"needn't\", 'can', 'which', 'herself', \"you're\", 't', 'isn', \"that'll\", 'each', 'why', \"haven't\", 'out', 'between', 'm', \"hadn't\", 'whom', 'our', 'its', 'won', 'against', 'itself', 'hadn', \"couldn't\", 'been', 'a', \"it's\", 'below', \"should've\", 'wouldn', \"doesn't\", 'doing', 'will', 'having', 'than', 'at', 'has', 'through', 'yourselves', 'shan', 'but', 'again', \"shouldn't\", 'above', \"mustn't\", 'him', \"won't\", 'an', 'hers', 'shouldn', \"don't\", 'she', 'ain', 'nor', \"you'll\", 'too', \"shan't\", 'it', 'do', 'ourselves', 'only', 'ours', 'to', 'such', 'needn', 'what', 'over', 'during', 'you', \"you've\", 'mustn', 'haven', 'off', 'because', 'themselves', 'same', 'he', 'some', 'her', 'll'}\n"
     ]
    }
   ],
   "source": [
    "#set stopwords to english\n",
    "stop=set(stopwords.words('english'))\n",
    "print(stop)\n",
    "\n",
    "#removing the stopwords\n",
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "#Apply function on review column\n",
    "df['review']=df['review'].apply(remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "063d9517",
   "metadata": {},
   "source": [
    "Normalized train reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "d2d58b0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'top valley mountain best place get pleasur realli love place see whole kathmandu valley best visit onc life must visit life get best experi life'"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#normalized train reviews\n",
    "norm_train_reviews=df.review[:4000]\n",
    "norm_train_reviews[0]\n",
    "#convert dataframe to string\n",
    "#norm_train_string=norm_train_reviews.to_string()\n",
    "#Spelling correction using Textblob\n",
    "#norm_train_spelling=TextBlob(norm_train_string)\n",
    "#norm_train_spelling.correct()\n",
    "#Tokenization using Textblob\n",
    "#norm_train_words=norm_train_spelling.words\n",
    "#norm_train_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d67648",
   "metadata": {},
   "source": [
    "**Normalized test reviews**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "170655a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalized test reviews\n",
    "norm_test_reviews=df.review[4000:]\n",
    "#norm_test_reviews[]\n",
    "##convert dataframe to string\n",
    "#norm_test_string=norm_test_reviews.to_string()\n",
    "#spelling correction using Textblob\n",
    "#norm_test_spelling=TextBlob(norm_test_string)\n",
    "#print(norm_test_spelling.correct())\n",
    "#Tokenization using Textblob\n",
    "#norm_test_words=norm_test_spelling.words\n",
    "#norm_test_words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fb362f",
   "metadata": {},
   "source": [
    "**Bags of words model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "fbc2886b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (4000, 54392)\n",
      "BOW_cv_test: (1401, 54392)\n"
     ]
    }
   ],
   "source": [
    "#Count vectorizer for bag of words\n",
    "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "cv_train_reviews=cv.fit_transform(norm_train_reviews)\n",
    "#transformed test reviews\n",
    "cv_test_reviews=cv.transform(norm_test_reviews)\n",
    "\n",
    "print('BOW_cv_train:',cv_train_reviews.shape)\n",
    "print('BOW_cv_test:',cv_test_reviews.shape)\n",
    "#vocab=cv.get_feature_names()-toget feature names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "475f62e4",
   "metadata": {},
   "source": [
    "**Term Frequency-Inverse Document Frequency model (TFIDF)**\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160ac937",
   "metadata": {},
   "source": [
    "It is used to convert text documents to matrix of tfidf features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "6ea07bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (4000, 54392)\n",
      "Tfidf_test: (1401, 54392)\n"
     ]
    }
   ],
   "source": [
    "#Tfidf vectorizer\n",
    "tv=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "tv_train_reviews=tv.fit_transform(norm_train_reviews)\n",
    "#transformed test reviews\n",
    "tv_test_reviews=tv.transform(norm_test_reviews)\n",
    "print('Tfidf_train:',tv_train_reviews.shape)\n",
    "print('Tfidf_test:',tv_test_reviews.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23eaed25",
   "metadata": {},
   "source": [
    "**Labeling the sentiment text**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "2a79b232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5401, 1)\n"
     ]
    }
   ],
   "source": [
    "#labeling the sentient data\n",
    "lb=LabelBinarizer()\n",
    "#transformed sentiment data\n",
    "sentiment_data=lb.fit_transform(df['sentiment_review'])\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72c20f1",
   "metadata": {},
   "source": [
    "**Split the sentiment tdata**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "369b0322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "[[1]\n",
      " [1]\n",
      " [0]\n",
      " ...\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "#Spliting the sentiment data\n",
    "train_sentiments=sentiment_data[:4000]\n",
    "test_sentiments=sentiment_data[4000:]\n",
    "print(train_sentiments)\n",
    "print(test_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be40d1",
   "metadata": {},
   "source": [
    "**Modelling the dataset**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3056685d",
   "metadata": {},
   "source": [
    "Let us build logistic regression model for both bag of words and tfidf features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "ed580414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n",
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "lr=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "#Fitting the model for Bag of words\n",
    "lr_bow=lr.fit(cv_train_reviews,train_sentiments)\n",
    "print(lr_bow)\n",
    "#Fitting the model for tfidf features\n",
    "lr_tfidf=lr.fit(tv_train_reviews,train_sentiments)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5e13dd",
   "metadata": {},
   "source": [
    "Logistic regression model performane on test dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "0713c293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "lr_bow_predict=lr.predict(cv_test_reviews)\n",
    "print(lr_bow_predict)\n",
    "##Predicting the model for tfidf features\n",
    "lr_tfidf_predict=lr.predict(tv_test_reviews)\n",
    "print(lr_tfidf_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cf59cd",
   "metadata": {},
   "source": [
    "**Accuracy of the model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "4f099d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_bow_score : 0.9550321199143469\n",
      "lr_tfidf_score : 0.9550321199143469\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for bag of words\n",
    "lr_bow_score=accuracy_score(test_sentiments,lr_bow_predict)\n",
    "print(\"lr_bow_score :\",lr_bow_score)\n",
    "#Accuracy score for tfidf features\n",
    "lr_tfidf_score=accuracy_score(test_sentiments,lr_tfidf_predict)\n",
    "print(\"lr_tfidf_score :\",lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310676db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b00d9876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.00      0.00      0.00        63\n",
      "    Negative       0.96      1.00      0.98      1338\n",
      "\n",
      "    accuracy                           0.96      1401\n",
      "   macro avg       0.48      0.50      0.49      1401\n",
      "weighted avg       0.91      0.96      0.93      1401\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.00      0.00      0.00        63\n",
      "    Negative       0.96      1.00      0.98      1338\n",
      "\n",
      "    accuracy                           0.96      1401\n",
      "   macro avg       0.48      0.50      0.49      1401\n",
      "weighted avg       0.91      0.96      0.93      1401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for bag of words \n",
    "lr_bow_report=classification_report(test_sentiments,lr_bow_predict,target_names=['Positive','Negative'])\n",
    "print(lr_bow_report)\n",
    "\n",
    "#Classification report for tfidf features\n",
    "lr_tfidf_report=classification_report(test_sentiments,lr_tfidf_predict,target_names=['Positive','Negative'])\n",
    "print(lr_tfidf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66f3803",
   "metadata": {},
   "source": [
    "Confusion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "22235167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1338    0]\n",
      " [  63    0]]\n",
      "[[1338    0]\n",
      " [  63    0]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,lr_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cm_tfidf=confusion_matrix(test_sentiments,lr_tfidf_predict,labels=[1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d69104",
   "metadata": {},
   "source": [
    "Stochastic gradient descent or Linear support vector machines for bag of words and tfidf features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "9276da0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier(max_iter=500, random_state=42)\n",
      "SGDClassifier(max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "#training the linear svm\n",
    "svm=SGDClassifier(loss='hinge',max_iter=500,random_state=42)\n",
    "#fitting the svm for bag of words\n",
    "svm_bow=svm.fit(cv_train_reviews,train_sentiments)\n",
    "print(svm_bow)\n",
    "#fitting the svm for tfidf features\n",
    "svm_tfidf=svm.fit(tv_train_reviews,train_sentiments)\n",
    "print(svm_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84355ae5",
   "metadata": {},
   "source": [
    "Model performance on test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "9e645051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "svm_bow_predict=svm.predict(cv_test_reviews)\n",
    "print(svm_bow_predict)\n",
    "#Predicting the model for tfidf features\n",
    "svm_tfidf_predict=svm.predict(tv_test_reviews)\n",
    "print(svm_tfidf_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2792e6d",
   "metadata": {},
   "source": [
    "Accuracy of the model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "860de1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svm_bow_score : 0.953604568165596\n",
      "svm_tfidf_score : 0.9550321199143469\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for bag of words\n",
    "svm_bow_score=accuracy_score(test_sentiments,svm_bow_predict)\n",
    "print(\"svm_bow_score :\",svm_bow_score)\n",
    "#Accuracy score for tfidf features\n",
    "svm_tfidf_score=accuracy_score(test_sentiments,svm_tfidf_predict)\n",
    "print(\"svm_tfidf_score :\",svm_tfidf_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94741033",
   "metadata": {},
   "source": [
    "Print the classification report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "231166c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.25      0.02      0.03        63\n",
      "    Negative       0.96      1.00      0.98      1338\n",
      "\n",
      "    accuracy                           0.95      1401\n",
      "   macro avg       0.60      0.51      0.50      1401\n",
      "weighted avg       0.92      0.95      0.93      1401\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Positive       0.00      0.00      0.00        63\n",
      "    Negative       0.96      1.00      0.98      1338\n",
      "\n",
      "    accuracy                           0.96      1401\n",
      "   macro avg       0.48      0.50      0.49      1401\n",
      "weighted avg       0.91      0.96      0.93      1401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for bag of words \n",
    "svm_bow_report=classification_report(test_sentiments,svm_bow_predict,target_names=['Positive','Negative'])\n",
    "print(svm_bow_report)\n",
    "#Classification report for tfidf features\n",
    "svm_tfidf_report=classification_report(test_sentiments,svm_tfidf_predict,target_names=['Positive','Negative'])\n",
    "print(svm_tfidf_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c7c833",
   "metadata": {},
   "source": [
    "Plot the confusion matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "662ca881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1335    3]\n",
      " [  62    1]]\n",
      "[[1338    0]\n",
      " [  63    0]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,svm_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cm_tfidf=confusion_matrix(test_sentiments,svm_tfidf_predict,labels=[1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80328374",
   "metadata": {},
   "source": [
    "Multinomial Naive Bayes for bag of words and tfidf features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "f88b0c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB()\n",
      "MultinomialNB()\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "mnb=MultinomialNB()\n",
    "#fitting the svm for bag of words\n",
    "mnb_bow=mnb.fit(cv_train_reviews,train_sentiments)\n",
    "print(mnb_bow)\n",
    "#fitting the svm for tfidf features\n",
    "mnb_tfidf=mnb.fit(tv_train_reviews,train_sentiments)\n",
    "print(mnb_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60d6e41b",
   "metadata": {},
   "source": [
    "Model performance on test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "7ec5d61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "[1 1 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "mnb_bow_predict=mnb.predict(cv_test_reviews)\n",
    "print(mnb_bow_predict)\n",
    "#Predicting the model for tfidf features\n",
    "mnb_tfidf_predict=mnb.predict(tv_test_reviews)\n",
    "print(mnb_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "1f4348b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mnb_bow_score : 0.9550321199143469\n",
      "mnb_tfidf_score : 0.9550321199143469\n"
     ]
    }
   ],
   "source": [
    "#Accuracy of the model\n",
    "#Accuracy score for bag of words\n",
    "mnb_bow_score=accuracy_score(test_sentiments,mnb_bow_predict)\n",
    "print(\"mnb_bow_score :\",mnb_bow_score)\n",
    "#Accuracy score for tfidf features\n",
    "mnb_tfidf_score=accuracy_score(test_sentiments,mnb_tfidf_predict)\n",
    "print(\"mnb_tfidf_score :\",mnb_tfidf_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "e1055d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.00      0.00      0.00        63\n",
      "    negative       0.96      1.00      0.98      1338\n",
      "\n",
      "    accuracy                           0.96      1401\n",
      "   macro avg       0.48      0.50      0.49      1401\n",
      "weighted avg       0.91      0.96      0.93      1401\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positive       0.00      0.00      0.00        63\n",
      "    negative       0.96      1.00      0.98      1338\n",
      "\n",
      "    accuracy                           0.96      1401\n",
      "   macro avg       0.48      0.50      0.49      1401\n",
      "weighted avg       0.91      0.96      0.93      1401\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification report for bag of words \n",
    "mnb_bow_report=classification_report(test_sentiments,mnb_bow_predict,target_names=['positive','negative'])\n",
    "print(mnb_bow_report)\n",
    "#Classification report for tfidf features\n",
    "mnb_tfidf_report=classification_report(test_sentiments,mnb_tfidf_predict,target_names=['positive','negative'])\n",
    "print(mnb_tfidf_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3da41dd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1338    0]\n",
      " [  63    0]]\n",
      "[[1338    0]\n",
      " [  63    0]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix for bag of words\n",
    "cm_bow=confusion_matrix(test_sentiments,mnb_bow_predict,labels=[1,0])\n",
    "print(cm_bow)\n",
    "#confusion matrix for tfidf features\n",
    "cm_tfidf=confusion_matrix(test_sentiments,mnb_tfidf_predict,labels=[1,0])\n",
    "print(cm_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61c57af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb3c3563",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5192e1f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f7d334",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
